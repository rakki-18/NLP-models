{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wmf07eJE8p9r"
   },
   "source": [
    "# Chatbot\n",
    "We are going to use the [Reformer](https://arxiv.org/abs/2001.04451), also known as the efficient Transformer, to generate a dialogue between two bots. You will feed conversations to your model and it will learn how to understand the context of each one. Not only will it learn how to answer questions but it will also know how to ask questions if it needs more info. For example, after a customer asks for a train ticket, the chatbot can ask what time the said customer wants to leave. You can use this concept to automate call centers, hotel receptions, personal trainers, or any type of customer service. \n",
    "\n",
    "* Understand how the Reformer works\n",
    "* Explore the [MultiWoz](https://arxiv.org/abs/1810.00278) dataset\n",
    "* Process the data to feed it into the model\n",
    "* Train your model\n",
    "* Generate a dialogue by feeding a question to the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27339,
     "status": "ok",
     "timestamp": 1607430694988,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "x3Yb5fa0VVSq",
    "outputId": "b9421606-4f66-4546-99d8-12431208908e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_MQwCvIVQpJ"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "# Part 1:   Exploring the MultiWoz dataset\n",
    "\n",
    "We will start by exploring the MultiWoz dataset. The dataset we are about to use has more than 10,000 human annotated dialogues and spans multiple domains and topics. Some dialogues include multiple domains and others include single domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETixln1SVQpJ"
   },
   "source": [
    "Let's first import the modules we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39249,
     "status": "ok",
     "timestamp": 1607430751811,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "aV4zpTnSVFIp",
    "outputId": "323a4ff6-a36e-44ce-cd68-3e44cfb40e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trax\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/1d/c0a3aeed127c26a0c3f0925fc9cc7278c272e52310eedfc322477e854972/trax-1.3.6-py2.py3-none-any.whl (468kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 5.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from trax) (0.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from trax) (1.18.5)\n",
      "Collecting tensorflow-text\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b2/2dbd90b93913afd07e6101b8b84327c401c394e60141c1e98590038060b3/tensorflow_text-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 16.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from trax) (1.4.1)\n",
      "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from trax) (0.17.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from trax) (1.15.0)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.6/dist-packages (from trax) (0.2.6)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from trax) (4.0.1)\n",
      "Collecting funcsigs\n",
      "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.6/dist-packages (from trax) (0.1.57+cuda101)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from trax) (0.10.0)\n",
      "Collecting t5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/39/a607d2450190af7675e4f77c5eff0cc9a83f82fe63fb396872ef2004106b/t5-0.7.1-py3-none-any.whl (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 33.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow<2.4,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->trax) (2.3.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->trax) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->trax) (1.3.0)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax->trax) (3.3.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (20.3.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (3.3.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (4.41.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.8)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.25.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.3.3)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (3.12.4)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.1.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (2.23.0)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.6/dist-packages (from jaxlib->trax) (1.12)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 38.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5->trax) (1.7.0+cu101)\n",
      "Collecting transformers>=2.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 29.4MB/s \n",
      "\u001b[?25hCollecting mesh-tensorflow[transformer]>=0.1.13\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8b/553deb763ce8d00afb17debab7cb14a87b209cd4c6f0e8ecfc8d884cb12a/mesh_tensorflow-0.1.17-py3-none-any.whl (342kB)\n",
      "\u001b[K     |████████████████████████████████| 348kB 44.3MB/s \n",
      "\u001b[?25hCollecting rouge-score\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5->trax) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5->trax) (0.22.2.post1)\n",
      "Collecting sacrebleu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 6.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5->trax) (1.1.4)\n",
      "Collecting tfds-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/b5/4b1d9cf76b8fb047563eca49c86e0fc74dc867c3f7ac9122486b939421c0/tfds_nightly-4.1.0.dev202012080107-py3-none-any.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 41.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5->trax) (3.2.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.33.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.12.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (2.10.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (2.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.3.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.35.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (2.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.2.0)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->trax) (3.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.52.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->trax) (50.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->t5->trax) (3.7.4.3)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 38.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (2019.12.20)\n",
      "Collecting tokenizers==0.9.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 41.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (20.4)\n",
      "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel->t5->trax) (2018.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->t5->trax) (0.17.0)\n",
      "Collecting portalocker\n",
      "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->t5->trax) (2.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.17.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5->trax) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.7.0->t5->trax) (2.4.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (2.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->trax) (0.4.8)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=e1995006bc7b33a7495fcea495804b86fd414a9746dcb2740bdfe316575233ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tensorflow-text, funcsigs, sentencepiece, sacremoses, tokenizers, transformers, mesh-tensorflow, rouge-score, portalocker, sacrebleu, tfds-nightly, t5, trax\n",
      "Successfully installed funcsigs-1.0.2 mesh-tensorflow-0.1.17 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.4.14 sacremoses-0.0.43 sentencepiece-0.1.94 t5-0.7.1 tensorflow-text-2.3.0 tfds-nightly-4.1.0.dev202012080107 tokenizers-0.9.4 transformers-4.0.0 trax-1.3.6\n",
      "trax                          1.3.6                \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "!pip install trax\n",
    "import trax   \n",
    "from trax import layers as tl\n",
    "from trax.supervised import training\n",
    "!pip list | grep trax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZwd4l-AVQpM"
   },
   "source": [
    "Let's also declare some constants we will be using in the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1011,
     "status": "ok",
     "timestamp": 1607431991559,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "l6sDRrDlVQpM"
   },
   "outputs": [],
   "source": [
    "# filename of the MultiWOZ dialogue dataset\n",
    "DATA_FILE = 'data.json'\n",
    "\n",
    "# data directory\n",
    "DATA_DIR = './data'\n",
    "\n",
    "# dictionary where we will load the dialogue dataset\n",
    "DIALOGUE_DB = {}\n",
    "\n",
    "# vocabulary filename\n",
    "VOCAB_FILE = 'en_32k.subword'\n",
    "\n",
    "# vocabulary file directory\n",
    "VOCAB_DIR = 'data/vocabs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX8WyOsQVQpM"
   },
   "source": [
    "Let's now load the MultiWOZ 2.1 dataset. We have already provided it for you in your workspace. It is in JSON format so we should load it as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 8600,
     "status": "ok",
     "timestamp": 1607432023439,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "K58I5vFB7GlP"
   },
   "outputs": [],
   "source": [
    "# help function to load a JSON file\n",
    "def load_json(directory, file):\n",
    "    with open(f'{directory}/{file}') as file: \n",
    "        db = json.load(file)\n",
    "    return db\n",
    "\n",
    "# load the dialogue data set into our dictionary\n",
    "DIALOGUE_DB = load_json(DATA_DIR, DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvmSdzF0VQpM"
   },
   "source": [
    "Let's see how many dialogues we have in the dictionary. 1 key-value pair is one dialogue so we can just get the dictionary's length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1607432024954,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "VGBnUfEk8p9x",
    "outputId": "70b9f5fe-c1d3-4fd8-d190-b8874ca57676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of dialogues is: 10438\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of dialogues is: {len(DIALOGUE_DB)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPgufwF2VQpN"
   },
   "source": [
    "The dialogues are composed of multiple files and the filenames are used as keys in our dictionary. Those with multi-domain dialogues have \"MUL\" in their filenames while single domain dialogues have either \"SNG\" or \"WOZ\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1607432028553,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "QdpHWbl_VQpN",
    "outputId": "2cbc6562-2c40-4d3d-95a8-57ad9aeee2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SNG01856.json', 'SNG0129.json', 'PMUL1635.json', 'MUL2168.json', 'SNG0073.json', 'SNG01445.json', 'MUL2105.json']\n"
     ]
    }
   ],
   "source": [
    "# print 7 keys from the dataset to see the filenames\n",
    "print(list(DIALOGUE_DB.keys())[0:7]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE6wiMUS8p91"
   },
   "source": [
    "As you can see from the cells above, there are 10,438 conversations, each in its own file.  You will train your model on all those conversations. Each file is also loaded into a dictionary and each has two keys which are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1287,
     "status": "ok",
     "timestamp": 1607432034735,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "5KYeQLnG8p96",
    "outputId": "dd932aef-42dd-41ac-94b4-3c75382f4b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['goal', 'log'])\n"
     ]
    }
   ],
   "source": [
    "# get keys of the fifth file in the list above\n",
    "print(DIALOGUE_DB['SNG0073.json'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-gj5aqF8p9_"
   },
   "source": [
    "The `goal` also points to a dictionary and it contains several keys pertaining to the objectives of the conversation. For example below, we can see that the conversation will be about booking a taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1607432038771,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "PPPWwQ2s8p9_",
    "outputId": "04bb86c3-3dae-4770-f6f7-13eae66671ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attraction': {},\n",
       " 'hospital': {},\n",
       " 'hotel': {},\n",
       " 'message': [\"You want to book a <span class='emphasis'>taxi</span>. The taxi should go to <span class='emphasis'>pizza hut fen ditton</span> and should depart from <span class='emphasis'>saint john's college</span>\",\n",
       "  \"The taxi should <span class='emphasis'>leave after 17:15</span>\",\n",
       "  \"Make sure you get <span class='emphasis'>car type</span> and <span class='emphasis'>contact number</span>\"],\n",
       " 'police': {},\n",
       " 'restaurant': {},\n",
       " 'taxi': {'fail_info': {},\n",
       "  'info': {'departure': \"saint john's college\",\n",
       "   'destination': 'pizza hut fen ditton',\n",
       "   'leaveAt': '17:15'},\n",
       "  'reqt': ['car type', 'phone']},\n",
       " 'train': {}}"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIALOGUE_DB['SNG0073.json']['goal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4N8RtWu8p-C"
   },
   "source": [
    "The `log` on the other hand contains the dialog. It is a list of dictionaries and each element of this list contains several descriptions as well. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1607432046159,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "eThYqsX2VQpO",
    "outputId": "830897b8-1626-4e8f-977e-d5f49c991aa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialog_act': {'Taxi-Inform': [['Dest', 'pizza hut fen ditton'],\n",
       "   ['Depart', \"saint john 's college\"]]},\n",
       " 'metadata': {},\n",
       " 'span_info': [['Taxi-Inform', 'Dest', 'pizza hut fen ditton', 11, 14],\n",
       "  ['Taxi-Inform', 'Depart', \"saint john 's college\", 6, 9]],\n",
       " 'text': \"I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first element of the log list\n",
    "DIALOGUE_DB['SNG0073.json']['log'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfGYorPhVQpO"
   },
   "source": [
    "For this assignment, we are only interested in the conversation which is in the `text` field.\n",
    "The conversation goes back and forth between two persons. Let's call them 'Person 1' and 'Person 2'. This implies that\n",
    "data['SNG0073.json']['log'][0]['text'] is 'Person 1' and\n",
    "data['SNG0073.json']['log'][1]['text'] is 'Person 2' and so on. The even offsets are 'Person 1' and the odd offsets are 'Person 2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1125,
     "status": "ok",
     "timestamp": 1607432049626,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "TatzJdttVQpO",
    "outputId": "e3b0a222-caab-423e-8dc9-d9c4a44c245f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Person 1:  I would like a taxi from Saint John's college to Pizza Hut Fen Ditton.\n",
      " Person 2:  What time do you want to leave and what time do you want to arrive by?\n"
     ]
    }
   ],
   "source": [
    "print(' Person 1: ', DIALOGUE_DB['SNG0073.json']['log'][0]['text'])\n",
    "print(' Person 2: ',DIALOGUE_DB['SNG0073.json']['log'][1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1081,
     "status": "ok",
     "timestamp": 1607432054437,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "RgdmUzTNVQpP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_conversation(file, data_db):\n",
    "    '''\n",
    "    Args:\n",
    "        file (string): filename of the dialogue file saved as json\n",
    "        data_db (dict): dialogue database\n",
    "    \n",
    "    Returns:\n",
    "        string: A string containing the 'text' fields of  data[file]['log'][x]\n",
    "    '''\n",
    "    \n",
    "    # initialize empty string\n",
    "    result = ''\n",
    "    \n",
    "    # get length of file's log list\n",
    "    len_msg_log = len(data_db[file]['log'])\n",
    "    \n",
    "    # set the delimiter strings\n",
    "    delimiter_1 = ' Person 1: '\n",
    "    delimiter_2 = ' Person 2: '\n",
    "    \n",
    "    # loop over the file's log list\n",
    "    for i in range(len_msg_log):\n",
    "        \n",
    "    \n",
    "    \n",
    "        # get i'th element of file log list\n",
    "        cur_log = data_db[file]['log'][i]\n",
    "        \n",
    "        # check if i is even\n",
    "        if i%2 == 0:                   \n",
    "            # append the 1st delimiter string\n",
    "            result += delimiter_1\n",
    "        else: \n",
    "            # append the 2nd delimiter string\n",
    "            result += delimiter_2\n",
    "        \n",
    "        # append the message text from the log\n",
    "        result += cur_log['text']\n",
    "    \n",
    "    \n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1022,
     "status": "ok",
     "timestamp": 1607432060891,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "Ugvx0noP8p-G",
    "outputId": "0c9ae638-4714-4061-be33-19c14ce786c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.\n",
      "Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.\n"
     ]
    }
   ],
   "source": [
    "file = 'SNG01856.json'\n",
    "conversation = get_conversation(file, DIALOGUE_DB)\n",
    "\n",
    "# print raw output\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9LTJTb3VQpQ"
   },
   "source": [
    "We can have a utility pretty print function just so we can visually follow the conversation more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1137,
     "status": "ok",
     "timestamp": 1607432072957,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "oBs9f1dmVQpQ",
    "outputId": "9bc1849c-ae45-4c4a-f47f-9c92a35ca94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPerson 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel \u001b[0m\n",
      "\u001b[32mPerson 2: Okay, do you have a specific area you want to stay in? \u001b[0m\n",
      "\u001b[31mPerson 1: no, i just need to make sure it's cheap. oh, and i need parking \u001b[0m\n",
      "\u001b[32mPerson 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? \u001b[0m\n",
      "\u001b[31mPerson 1: Yes, please. 6 people 3 nights starting on tuesday. \u001b[0m\n",
      "\u001b[32mPerson 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? \u001b[0m\n",
      "\u001b[31mPerson 1: how about only 2 nights. \u001b[0m\n",
      "\u001b[32mPerson 2: Booking was successful.\n",
      "Reference number is : 7GAWK763. Anything else I can do for you? \u001b[0m\n",
      "\u001b[31mPerson 1: No, that will be all. Good bye. \u001b[0m\n",
      "\u001b[32mPerson 2: Thank you for using our services.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def print_conversation(conversation):\n",
    "    \n",
    "    delimiter_1 = 'Person 1: '\n",
    "    delimiter_2 = 'Person 2: '\n",
    "    \n",
    "    split_list_d1 = conversation.split(delimiter_1)\n",
    "    \n",
    "    for sublist in split_list_d1[1:]:\n",
    "        split_list_d2 = sublist.split(delimiter_2)\n",
    "        print(colored(f'Person 1: {split_list_d2[0]}', 'red'))\n",
    "        \n",
    "        if len(split_list_d2) > 1:\n",
    "            print(colored(f'Person 2: {split_list_d2[1]}', 'green'))\n",
    "\n",
    "            \n",
    "print_conversation(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1039,
     "status": "ok",
     "timestamp": 1607432079734,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "Rs2R8q1d8p-K",
    "outputId": "10f4409b-250d-4585-a9ca-338ca4d54199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialog_act': {'Hotel-Inform': [['Type', 'hotel'], ['Price', 'cheap']]},\n",
       " 'metadata': {},\n",
       " 'span_info': [['Hotel-Inform', 'Type', 'hotel', 20, 20],\n",
       "  ['Hotel-Inform', 'Price', 'cheap', 10, 10]],\n",
       " 'text': 'am looking for a place to to stay that has cheap price range it should be in a type of hotel'}"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DIALOGUE_DB['SNG01856.json']['log'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf0AAmxy8p-N"
   },
   "source": [
    "The dataset also comes with hotel, hospital, taxi, train, police, and restaurant databases. For example, in case you need to call a doctor, or a hotel, or a taxi, this will allow you to automate the entire conversation. Take a look at the files accompanying the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1607432083243,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "HQmYUcsi8p-O",
    "outputId": "24825ce9-9495-4aa9-ffd4-b9e271ae2ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': 'pool way, whitehill road, off newmarket road', 'area': 'east', 'entrance fee': '?', 'id': '1', 'location': [52.208789, 0.154883], 'name': 'abbey pool and astroturf pitch', 'openhours': '?', 'phone': '01223902088', 'postcode': 'cb58nt', 'pricerange': '?', 'type': 'swimmingpool'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of the attractions file\n",
    "attraction_file = open('data/attraction_db.json')\n",
    "attractions = json.load(attraction_file)\n",
    "print(attractions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1607432084331,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "I5kTg4uX8p-R",
    "outputId": "9a4ef343-9c00-4af8-ac74-7728251e81dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'department': 'neurosciences critical care unit', 'id': 0, 'phone': '01223216297'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of the hospital file\n",
    "hospital_file = open('data/hospital_db.json')\n",
    "hospitals = json.load(hospital_file)\n",
    "print(hospitals[0]) # feel free to index into other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1607432091527,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "B5knaAEc8p-U",
    "outputId": "fbfbe0cf-fc8e-4f11-9899-bcf3af1a5e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': '124 tenison road', 'area': 'east', 'internet': 'yes', 'parking': 'no', 'id': '0', 'location': [52.1963733, 0.1987426], 'name': 'a and b guest house', 'phone': '01223315702', 'postcode': 'cb12dp', 'price': {'double': '70', 'family': '90', 'single': '50'}, 'pricerange': 'moderate', 'stars': '4', 'takesbookings': 'yes', 'type': 'guesthouse'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of the hotel file\n",
    "hotel_file = open('data/hotel_db.json')\n",
    "hotels = json.load(hotel_file)\n",
    "print(hotels[0]) # feel free to index into other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1607432094069,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "t-Rk01Mv8p-a",
    "outputId": "9b6dd02f-98d1-48f4-fda4-ba6f8161a526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Parkside Police Station', 'address': 'Parkside, Cambridge', 'id': 0, 'phone': '01223358966'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of the police file\n",
    "police_file = open('data/police_db.json')\n",
    "police = json.load(police_file)\n",
    "print(police[0]) # feel free to index into other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1421,
     "status": "ok",
     "timestamp": 1607432096481,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "u-G9pD8g8p-d",
    "outputId": "2943c1f5-e44a-4ce1-c4b8-00d55dab46f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': 'Regent Street City Centre', 'area': 'centre', 'food': 'italian', 'id': '19210', 'introduction': 'Pizza hut is a large chain with restaurants nationwide offering convenience pizzas pasta and salads to eat in or take away', 'location': [52.20103, 0.126023], 'name': 'pizza hut city centre', 'phone': '01223323737', 'postcode': 'cb21ab', 'pricerange': 'cheap', 'type': 'restaurant'}\n"
     ]
    }
   ],
   "source": [
    "# this is an example of a restuarant file\n",
    "restaurant_file = open('data/restaurant_db.json')\n",
    "restaurants = json.load(restaurant_file)\n",
    "print(restaurants[0]) # feel free to index into other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9eAKw4R8p-g"
   },
   "source": [
    "For more information about the multiwoz 2.1 data set, please run the cell below to read the `ReadMe.txt` file. Feel free to open any other file to explore it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1637,
     "status": "ok",
     "timestamp": 1607432099100,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "2H8pB_yI8p-g",
    "outputId": "6d60b8da-c663-4510-9d6c-ffc4243d95c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################\n",
      "#####################################################\n",
      "#  Copyright Cambridge Dialogue Systems Group, 2018 #\n",
      "#####################################################\n",
      "#####################################################\n",
      "\n",
      "Dataset contains the following files:\n",
      "1. data.json: the woz dialogue dataset, which contains the conversation  users and wizards, as well as a set of coarse labels for each user turn. This file contains both system and user dialogue acts annotated at the turn level. Files with multi-domain dialogues have \"MUL\" in their names. Single domain dialogues have either \"SNG\" or \"WOZ\" in their names.\n",
      "2. restaurant_db.json: the Cambridge restaurant database file, containing restaurants in the Cambridge UK area and a set of attributes.\n",
      "3. attraction_db.json: the Cambridge attraction database file, contining attractions in the Cambridge UK area and a set of attributes.\n",
      "4. hotel_db.json: the Cambridge hotel database file, containing hotels in the Cambridge UK area and a set of attributes.\n",
      "5. train_db.json: the Cambridge train (with artificial connections) database file, containing trains in the Cambridge UK area and a set of attributes.\n",
      "6. hospital_db.json: the Cambridge hospital database file, contatining information about departments.\n",
      "7. police_db.json: the Cambridge police station information.\n",
      "8. taxi_db.json: slot-value list for taxi domain.\n",
      "9. valListFile.txt: list of dialogues for validation.\n",
      "10. testListFile.txt: list of dialogues for testing.\n",
      "11. system_acts.json:\n",
      "  There are 6 domains ('Booking', 'Restaurant', 'Hotel', 'Attraction', 'Taxi', 'Train') and 1 dummy domain ('general').\n",
      "  A domain-dependent dialogue act is defined as a domain token followed by a domain-independent dialogue act, e.g. 'Hotel-inform' means it is an 'inform' act in the Hotel domain.\n",
      "  Dialogue acts which cannot take slots, e.g., 'good bye', are defined under the 'general' domain.\n",
      "  A slot-value pair defined as a list with two elements. The first element is slot token and the second one is its value.\n",
      "  If a dialogue act takes no slots, e.g., dialogue act 'offer booking' for an utterance 'would you like to take a reservation?', its slot-value pair is ['none', 'none']\n",
      "  There are four types of values:\n",
      "  1) If a slot takes a binary value, e.g., 'has Internet' or 'has park', the value is either 'yes' or 'no'.\n",
      "  2) If a slot is under the act 'request', e.g., 'request' about 'area', the value is expressed as '?'.\n",
      "  3) The value that appears in the utterance e.g., the name of a restaurant.\n",
      "  4) If for some reason the turn does not have an annotation then it is labeled as \"No Annotation.\"\n",
      "12. ontology.json: Data-based ontology containing all the values for the different slots in the domains.\n",
      "13. slot_descriptions.json: A collection of human-written slot descriptions for each slot in the dataset. Each slot has at least two descriptions.\n",
      "14. tokenization.md: A description of the tokenization preprocessing we had to perform to maintain consistency between the dialogue act annotations of DSTC 8 Track 1 and the existing MultiWOZ 2.0 data. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/README') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz5XtX50VQpS"
   },
   "source": [
    "As you can see, there are many other aspects of the MultiWoz dataset. Nonetheless, you'll see that even with just the conversations, your model will still be able to generate useful responses. This concludes our exploration of the dataset. In the next section, we will do some preprocessing before we feed it into our model for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juJWkQI_8p-j"
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "# Part 2:   Processing the data for Reformer inputs\n",
    "\n",
    "You will now use the `get_conversation()` function to process the data. The Reformer expects inputs of this form: \n",
    "\n",
    "**Person 1: Why am I so happy? Person 2: Because you are learning NLP Person 1: ... Person 2: ...***\n",
    "\n",
    "And the conversation keeps going with some text. As you can see 'Person 1' and 'Person 2' act as delimiters so the model automatically recognizes the person and who is talking. It can then come up with the corresponding text responses for each person. Let's proceed to process the text in this fashion for the Reformer. First, let's grab all the conversation strings from all dialogue files and put them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1607432102952,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "IrnQ9eNV8p-k",
    "outputId": "073c3cf3-ac12-4277-9362-cfee086dddd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Person 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel Person 2: Okay, do you have a specific area you want to stay in? Person 1: no, i just need to make sure it's cheap. oh, and i need parking Person 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? Person 1: Yes, please. 6 people 3 nights starting on tuesday. Person 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? Person 1: how about only 2 nights. Person 2: Booking was successful.\n",
      "Reference number is : 7GAWK763. Anything else I can do for you? Person 1: No, that will be all. Good bye. Person 2: Thank you for using our services.\n"
     ]
    }
   ],
   "source": [
    "# the keys are the file names\n",
    "all_files = DIALOGUE_DB.keys()\n",
    "\n",
    "# initialize empty list\n",
    "untokenized_data = []\n",
    "\n",
    "# loop over all files\n",
    "for file in all_files:\n",
    "    # this is the graded function you coded\n",
    "    # returns a string delimited by Person 1 and Person 2\n",
    "    result = get_conversation(file, DIALOGUE_DB)\n",
    "    \n",
    "    # append to the list\n",
    "    untokenized_data.append(result)\n",
    "\n",
    "# print the first element to check if it's the same as the one we got before\n",
    "print(untokenized_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55kki_ezVQpS"
   },
   "source": [
    "Now let us split the list to a train and eval dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1607432104822,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "buE0b8bjx_p_",
    "outputId": "9acb2ab0-3568-4f4b-fd03-6e9cc665ea4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of conversations in the data set: 10438\n",
      "number of conversations in train set: 9917\n",
      "number of conversations in eval set: 521\n"
     ]
    }
   ],
   "source": [
    "# shuffle the list we generated above\n",
    "random.shuffle(untokenized_data)\n",
    "\n",
    "# define a cutoff (5% of the total length for this assignment)\n",
    "# convert to int because we will use it as a list index\n",
    "cut_off = int(len(untokenized_data) * .05)\n",
    "\n",
    "# slice the list. the last elements after the cut_off value will be the eval set. the rest is for training. \n",
    "train_data, eval_data = untokenized_data[:-cut_off], untokenized_data[-cut_off:]\n",
    "\n",
    "print(f'number of conversations in the data set: {len(untokenized_data)}')\n",
    "print(f'number of conversations in train set: {len(train_data)}')\n",
    "print(f'number of conversations in eval set: {len(eval_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4R9gwc5VQpS"
   },
   "source": [
    "<a name=\"2.1\"></a>\n",
    "## 2.1   Tokenizing, batching with bucketing\n",
    "We can now proceed in generating tokenized batches of our data. Let's first define a utility generator function to yield elements from our data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 1075,
     "status": "ok",
     "timestamp": 1607432107132,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "KoGpITddVQpS"
   },
   "outputs": [],
   "source": [
    "def stream(data):\n",
    "    # loop over the entire data\n",
    "    while True:\n",
    "        # get a random element\n",
    "        d = random.choice(data)\n",
    "        \n",
    "        # yield a tuple pair of identical values \n",
    "        # (i.e. our inputs to the model will also be our targets during training)\n",
    "        yield (d, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlgNlcBOVQpS"
   },
   "source": [
    "Now let's define our data pipeline for tokenizing and batching our data. As in the previous assignments, we will bucket by length and also have an upper bound on the token length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1607432109528,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "uZgK5FAAWwOu"
   },
   "outputs": [],
   "source": [
    "# trax allows us to use combinators to generate our data pipeline\n",
    "data_pipeline = trax.data.Serial(\n",
    "    # randomize the stream\n",
    "    trax.data.Shuffle(),\n",
    "    \n",
    "    # tokenize the data\n",
    "    trax.data.Tokenize(vocab_dir=VOCAB_DIR,\n",
    "                       vocab_file=VOCAB_FILE),\n",
    "    \n",
    "    # filter too long sequences\n",
    "    trax.data.FilterByLength(2048),\n",
    "    \n",
    "    # bucket by length\n",
    "    trax.data.BucketByLength(boundaries=[128, 256,  512, 1024],\n",
    "                             batch_sizes=[16,    8,    4,   2, 1]),\n",
    "    \n",
    "    # add loss weights but do not add it to the padding tokens (i.e. 0)\n",
    "    trax.data.AddLossWeights(id_to_mask=0)\n",
    ")\n",
    "\n",
    "# apply the data pipeline to our train and eval sets\n",
    "train_stream = data_pipeline(stream(train_data))\n",
    "eval_stream = data_pipeline(stream(eval_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwFEbYuiYqbo"
   },
   "source": [
    "Peek into the train stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1797,
     "status": "ok",
     "timestamp": 1607432114239,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "9iBQEvhLYRot",
    "outputId": "0f5d8b37-cab0-4df2-bafc-1c29139369a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (4, 512)\n",
      " Person 1: I'm looking for a moderately priced place to eat in the North please Person 2: There's a restaurant that serves chinese and a restaurant that serves indian food. Will one of those work for you? Person 1: I would prefer the Indian restaurant please. Person 2: Okay. Would you like for me to make a reservation there? Person 1: Yes. Can you book for 8 people at 19:15 on Monday? Person 2: Ok, you're booked, the table will be reserved for 15 minutes. Reference number is : 7Y3YQNNR.\n",
      "\n",
      " Person 1: I also need to get a train.  Person 2: Alright when would you like to leave by? Person 1: I want the train from birmingham new street to arrive in cambridge by 09:30. I plan to travel on monday. Please provide me with the travel time for this trip Person 2: There are 4 options. The travel time for each trip is 163 minutes. Person 1: Get the earliest one, please.  Person 2: The earliest train leaves at 05:40 and arrives 08:23. The price is 75.10 pounds and travel time 163 minutes. Do you want to book, and if so for how many people? Person 1: Yes I would like to book, for 8 people. Person 2: Okay, it is booked. Reference number is VSTQEJ0S Person 1: Thank you for all of your help! Person 2: Thanks, have a great trip!\n"
     ]
    }
   ],
   "source": [
    "# the stream generators will yield (input, target, weights). let's just grab the input for inspection\n",
    "inp, _, _ = next(train_stream)\n",
    "\n",
    "# print the shape. format is (batch size, token length)\n",
    "print(\"input shape: \", inp.shape)\n",
    "\n",
    "# detokenize the first element\n",
    "print(trax.data.detokenize(inp[0], vocab_dir=VOCAB_DIR, vocab_file=VOCAB_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J_0ZDc_18cL"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "# Part 3:   Reversible layers\n",
    "\n",
    "When running large deep models, you will often run out of memory as each layer allocates memory to store activations for use in backpropagation. To save this resource, you need to be able to recompute these activations during the backward pass without storing them during the forward pass. Take a look first at the leftmost diagram below. \n",
    "\n",
    "\n",
    "\n",
    "This is how the residual networks are implemented in the standard Transformer. It follows that, given `F()` is Attention and `G()` is Feed-forward(FF). \n",
    ": \n",
    "\n",
    "\\begin{align}  \n",
    "\\mathrm{y}_\\mathrm{a} &= \\mathrm{x} + \\mathrm{F}\\left(\\mathrm{x}\\right)\\tag{1} \\\\\n",
    "\\mathrm{y}_{b}&=\\mathrm{y}_{a}+\\mathrm{G}\\left(\\mathrm{y}_{a}\\right)\\tag{2}\\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "As you can see, it requires that $\\mathrm{x}$ and $\\mathrm{y}_{a}$ be saved so it can be used during backpropagation. We want to avoid this to conserve memory and this is where reversible residual connections come in. They are shown in the middle and rightmost diagrams above. The key idea is that we will start with two copies of the input to the model and at each layer we will only update one of them. The activations that we *don’t* update are the ones that will be used to compute the residuals. \n",
    "\n",
    "Now in this reversible set up you get the following instead: \n",
    "\n",
    "\\begin{align}  \n",
    "\\mathrm{y}_{1}&=\\mathrm{x}_{1}+\\mathrm{F}\\left(\\mathrm{x}_{2}\\right)\\tag{3}\\\\\n",
    "\\mathrm{y}_{2}&=\\mathrm{x}_{2}+\\mathrm{G}\\left(\\mathrm{y}_{1}\\right)\\tag{4}\\\\\n",
    "\\end{align}\n",
    "To recover $\\mathrm{(x_1,x_2)}$ from $\\mathrm{(y_1, y_2)}$ \n",
    "\n",
    "\\begin{align}  \n",
    "\\mathrm{x}_{2}&=\\mathrm{y}_{2}-\\mathrm{G}\\left(\\mathrm{y}_{1}\\right)\\tag{5}\\\\\n",
    "\\mathrm{x}_{1}&=\\mathrm{y}_{1}-\\mathrm{F}\\left(\\mathrm{x}_{2}\\right)\\tag{6}\\\\\n",
    "\\end{align}\n",
    "\n",
    "With this configuration, we’re now able to run the network fully in reverse. You'll notice that during the backward pass, $\\mathrm{x2}$ and $\\mathrm{x1}$ can be recomputed based solely on the values of $\\mathrm{y2}$ and $\\mathrm{y1}$. No need to save it during the forward pass.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 1192,
     "status": "ok",
     "timestamp": 1607432115567,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "adX2eU762BkF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def reversible_layer_forward(x, f, g):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        x (np.array): an input vector or matrix\n",
    "        f (function): a function which operates on a vector/matrix\n",
    "        g (function): a function which operates on a vector/matrix\n",
    "    Returns: \n",
    "        y (np.array): an output vector or matrix whose form is determined by 'x', f and g\n",
    "    \"\"\"\n",
    "    # split the input vector into two (* along the last axis because it is the depth dimension)\n",
    "    x1, x2 = np.split(x, 2, axis=-1) \n",
    "    \n",
    "        \n",
    "    # get y1 using equation 3\n",
    "    y1 = x1 + f(x2)\n",
    "    \n",
    "    # get y2 using equation 4\n",
    "    y2 = x2 + g(y1)\n",
    "    \n",
    "    # concatenate y1 and y2 along the depth dimension. be sure output is of type np.ndarray\n",
    "    y = np.concatenate([y1, y2], axis=-1)\n",
    "    \n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1607432117621,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "0xTCG9WlaiiO"
   },
   "outputs": [],
   "source": [
    "\n",
    "def reversible_layer_reverse(y, f, g):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y (np.array): an input vector or matrix\n",
    "        f (function): a function which operates on a vector/matrix of the form of 'y'\n",
    "        g (function): a function which operates on a vector/matrix of the form of 'y'\n",
    "    Returns: \n",
    "        y (np.array): an output vector or matrix whose form is determined by 'y', f and g\n",
    "    \"\"\"\n",
    "    \n",
    "    # split the input vector into two (* along the last axis because it is the depth dimension)\n",
    "    y1, y2 = np.split(y, 2, axis=-1)\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
    "    \n",
    "    # compute x2 using equation 5\n",
    "    x2 = y2 - g(y1)\n",
    "    \n",
    "    # compute x1 using equation 6\n",
    "    x1 = y1 - f(x2)\n",
    "    \n",
    "    # concatenate x1 and x2 along the depth dimension\n",
    "    x = np.concatenate([x1, x2], axis=-1)\n",
    "    \n",
    "    \n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1607432119669,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "o66C0Nfoafjf"
   },
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: assert at the end can be used in grading as well\n",
    "f = lambda x: x + 2\n",
    "g = lambda x: x * 3\n",
    "input_vector = np.random.uniform(size=(32,))\n",
    "\n",
    "output_vector = reversible_layer_forward(input_vector, f, g)\n",
    "reversed_vector = reversible_layer_reverse(output_vector, f, g)\n",
    "\n",
    "assert np.allclose(reversed_vector, input_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSRjn82B3Sh8"
   },
   "source": [
    "<a name=\"3.1\"></a>\n",
    "## 3.1   Reversible layers and randomness\n",
    "\n",
    "This is why we were learning about fastmath's random functions and keys in Course 3 Week 1. Utilizing the same key, `trax.fastmath.random.uniform()` will return the same values. This is required for the backward pass to return the correct layer inputs when random noise is introduced in the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1729,
     "status": "ok",
     "timestamp": 1607432122742,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "IjElqUtc2BYG",
    "outputId": "49553f14-2507-4e99-ba21-0fd7682319e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Layers like dropout have noise, so let's simulate it here:\n",
    "f = lambda x: x + np.random.uniform(size=x.shape)\n",
    "\n",
    "# See that the above doesn't work any more:\n",
    "output_vector = reversible_layer_forward(input_vector, f, g)\n",
    "reversed_vector = reversible_layer_reverse(output_vector, f, g)\n",
    "\n",
    "assert not np.allclose(reversed_vector, input_vector)  # Fails!!\n",
    "\n",
    "# It failed because the noise when reversing used a different random seed.\n",
    "\n",
    "random_seed = 27686\n",
    "rng = trax.fastmath.random.get_prng(random_seed)\n",
    "f = lambda x: x + trax.fastmath.random.uniform(key=rng, shape=x.shape)\n",
    "\n",
    "# See that it works now as the same rng is used on forward and reverse.\n",
    "output_vector = reversible_layer_forward(input_vector, f, g)\n",
    "reversed_vector = reversible_layer_reverse(output_vector, f, g)\n",
    "\n",
    "assert np.allclose(reversed_vector, input_vector,  atol=1e-07) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsfaBEyd4Ks4"
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "# Part 4:   ReformerLM Training\n",
    "\n",
    "We will now proceed to training our model. Since we have already know the two main components that differentiates it from the standard Transformer, LSH in Course 1 and reversible layers above, we can just use the pre-built model already implemented in Trax. It will have this architecture:\n",
    "\n",
    "\n",
    "\n",
    "Similar to the Transformer we learned earlier, we want to apply an attention and feed forward layer to your inputs. For the Reformer, we improve the memory efficiency by using **reversible decoder blocks** and youwecan picture its implementation in Trax like below:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHWmZMFbVQpU"
   },
   "source": [
    "<a name=\"ex04\"></a>\n",
    "### Exercise 04\n",
    "**Instructions:** Implement a wrapper function that returns a Reformer Language Model. You can use Trax's [ReformerLM](https://trax-ml.readthedocs.io/en/latest/trax.models.html#trax.models.reformer.reformer.ReformerLM) to do this quickly. It will have the same architecture as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1607432125201,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "RidbAcoR6duP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def ReformerLM(vocab_size=33000, n_layers=2, mode='train', attention_type=tl.SelfAttention):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        vocab_size (int): size of the vocabulary\n",
    "        n_layers (int): number of decoder layers\n",
    "        mode (string): setting of the model which can be 'train', 'eval', or 'predict' \n",
    "        attention_type(class): attention class to use \n",
    "    Returns: \n",
    "        model (ReformerLM): a reformer language model implemented in Trax\n",
    "    \"\"\"    \n",
    "    \n",
    "    \n",
    "    # initialize an instance of Trax's ReformerLM class\n",
    "    model = trax.models.reformer.ReformerLM( \n",
    "        # set vocab size\n",
    "        vocab_size=vocab_size,\n",
    "        # set number of layers\n",
    "        n_layers=n_layers,\n",
    "        # set mode\n",
    "        mode=mode,\n",
    "        # set attention type\n",
    "        attention_type=attention_type\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1150,
     "status": "ok",
     "timestamp": 1607432127337,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "_ffmu8aoVQpU",
    "outputId": "030bb3c6-4dfe-4189-fa22-52690688dd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Serial[\n",
      "    AssertShape\n",
      "    ShiftRight(1)\n",
      "    AssertShape\n",
      "  ]\n",
      "  Embedding_train_512\n",
      "  Dropout\n",
      "  PositionalEncoding\n",
      "  Dup_out2\n",
      "  ReversibleSerial_in2_out2[\n",
      "    ReversibleHalfResidual_in2_out2[\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "      ]\n",
      "      SelfAttention\n",
      "    ]\n",
      "    ReversibleSwap_in2_out2\n",
      "    ReversibleHalfResidual_in2_out2[\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Dense_2048\n",
      "        Dropout\n",
      "        FastGelu\n",
      "        Dense_512\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    ReversibleSwap_in2_out2\n",
      "    ReversibleHalfResidual_in2_out2[\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "      ]\n",
      "      SelfAttention\n",
      "    ]\n",
      "    ReversibleSwap_in2_out2\n",
      "    ReversibleHalfResidual_in2_out2[\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Dense_2048\n",
      "        Dropout\n",
      "        FastGelu\n",
      "        Dense_512\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    ReversibleSwap_in2_out2\n",
      "  ]\n",
      "  Concatenate_in2\n",
      "  LayerNorm\n",
      "  Dropout\n",
      "  Dense_train\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# display the model\n",
    "temp_model = ReformerLM('train')\n",
    "print(str(temp_model))\n",
    "\n",
    "# free memory\n",
    "del temp_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKu0pmtiVQpV"
   },
   "source": [
    "\n",
    "\n",
    "- Create `TrainTask` and `EvalTask`\n",
    "- Create the training loop `trax.supervised.training.Loop`\n",
    "- Pass in the following depending to train_task :\n",
    "    - `labeled_data=train_gen`\n",
    "    - `loss_layer=tl.CrossEntropyLoss()`\n",
    "    - `optimizer=trax.optimizers.Adam(0.01)`\n",
    "    - `lr_schedule=lr_schedule`\n",
    "    - `n_steps_per_checkpoint=10`  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 1320,
     "status": "ok",
     "timestamp": 1607432137484,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "tQehGhoD4Psl"
   },
   "outputs": [],
   "source": [
    "\n",
    "def training_loop(ReformerLM, train_gen, eval_gen, output_dir = \"./model/\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ReformerLM:  the Reformer language model you are building\n",
    "        train_gen (generator): train data generator.\n",
    "        eval_gen (generator): Validation generator. \n",
    "        output_dir (string): Path to save the model output. Defaults to './model/'.\n",
    "\n",
    "    Returns:\n",
    "        trax.supervised.training.Loop: Training loop for the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # use the warmup_and_rsqrt_decay learning rate schedule\n",
    "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(\n",
    "        n_warmup_steps=1000, max_value=0.01)\n",
    "\n",
    "\n",
    "    \n",
    "    # define the train task\n",
    "    train_task = training.TrainTask(            \n",
    "        # labeled data\n",
    "        labeled_data=train_gen,\n",
    "        # loss layer\n",
    "        loss_layer=tl.CrossEntropyLoss(),\n",
    "        # optimizer\n",
    "        optimizer=trax.optimizers.Adam(0.01),\n",
    "        # lr_schedule\n",
    "        lr_schedule=lr_schedule,\n",
    "        # n_steps\n",
    "        n_steps_per_checkpoint=10\n",
    "    )\n",
    "\n",
    "    # define the eval task\n",
    "    eval_task = training.EvalTask(                      \n",
    "        # labeled data\n",
    "        labeled_data=eval_gen,\n",
    "        # metrics\n",
    "        metrics=[tl.CrossEntropyLoss(), tl.Accuracy()]\n",
    "    )\n",
    "\n",
    "    \n",
    "    loop = training.Loop(ReformerLM(mode='train'),\n",
    "                         train_task,\n",
    "                         eval_tasks=[eval_task],\n",
    "                         output_dir=output_dir)\n",
    "    return loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311510,
     "status": "ok",
     "timestamp": 1607434832094,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "p9jERXY46I6J",
    "outputId": "cbc8dad3-6090-4442-8609-50d7e89b87fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 58072296\n",
      "Step      1: Ran 1 train steps in 71.82 secs\n",
      "Step      1: train CrossEntropyLoss |  10.42980957\n",
      "Step      1: eval  CrossEntropyLoss |  10.39183235\n",
      "Step      1: eval          Accuracy |  0.00000000\n",
      "\n",
      "Step     10: Ran 9 train steps in 213.35 secs\n",
      "Step     10: train CrossEntropyLoss |  10.19278431\n",
      "Step     10: eval  CrossEntropyLoss |  9.78180218\n",
      "Step     10: eval          Accuracy |  0.05691554\n"
     ]
    }
   ],
   "source": [
    "# we will now test your function\n",
    "!rm -f model/model.pkl.gz\n",
    "loop = training_loop(ReformerLM, train_stream, eval_stream)\n",
    "loop.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAGlkMZW6rKn"
   },
   "source": [
    "<a name=\"5\"></a>\n",
    "# Part 5:   Decode from a pretrained model\n",
    "\n",
    "We will now proceed on decoding using the model architecture you just implemented. As in the previous weeks, we will be giving you a pretrained model so you can observe meaningful output during inference. You will be using the [autoregressive_sample_stream()](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.decoding.autoregressive_sample_stream) decoding method from Trax to do fast inference. Let's define a few parameters to initialize our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 1205,
     "status": "ok",
     "timestamp": 1607436285937,
     "user": {
      "displayName": "Rakshit p",
      "photoUrl": "",
      "userId": "13346933554622736891"
     },
     "user_tz": -330
    },
    "id": "vNFQKw53VQpW"
   },
   "outputs": [],
   "source": [
    "# define the `predict_mem_len` and `predict_drop_len` of tl.SelfAttention\n",
    "def attention(*args, **kwargs):\n",
    "    # number of input positions to remember in a cache when doing fast inference. \n",
    "    kwargs['predict_mem_len'] = 120\n",
    "    # number of input elements to drop once the fast inference input cache fills up.\n",
    "    kwargs['predict_drop_len'] = 120\n",
    "    # return the attention layer with the parameters defined above\n",
    "    return tl.SelfAttention(*args, **kwargs)\n",
    "\n",
    "# define the model using the ReformerLM function you implemented earlier.\n",
    "model = ReformerLM(\n",
    "    vocab_size=33000,\n",
    "    n_layers=6,\n",
    "    mode='predict',\n",
    "    attention_type=attention,\n",
    ")\n",
    "\n",
    "# define an input signature so we can initialize our model. shape will be (1, 1) and the data type is int32.\n",
    "shape11 = trax.shapes.ShapeDtype((1, 1), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7n1iOnHuVQpW"
   },
   "source": [
    "We can now initialize our model from a file containing the pretrained weights. We will save this starting state so we can reset the model state when we generate a new conversation. This will become clearer in the `generate_dialogue()` function later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPDwDAK2VQpW"
   },
   "source": [
    "Let's define a few utility functions as well to help us tokenize and detokenize. We can use the [tokenize()](https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.tokenize) and [detokenize()](https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.detokenize) from `trax.data.tf_inputs` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SeJeF4iVQpW"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence, vocab_file, vocab_dir):\n",
    "    return list(trax.data.tokenize(iter([sentence]), vocab_file=vocab_file, vocab_dir=vocab_dir))[0]\n",
    "\n",
    "def detokenize(tokens, vocab_file, vocab_dir):\n",
    "    return trax.data.detokenize(tokens, vocab_file=vocab_file, vocab_dir=vocab_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV4Q4xcDVQpW"
   },
   "source": [
    "We are now ready to define our decoding function. This will return a generator that yields that next symbol output by the model. It will be able to predict the next words by just feeding it a starting sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DrL5RkeVQpW"
   },
   "outputs": [],
   "source": [
    "\n",
    "def ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file, vocab_dir, temperature):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ReformerLM:  the Reformer language model you just trained\n",
    "        start_sentence (string): starting sentence of the conversation\n",
    "        vocab_file (string): vocabulary filename\n",
    "        vocab_dir (string): directory of the vocabulary file\n",
    "        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n",
    "            0.0: same as argmax, always pick the most probable token\n",
    "            1.0: sampling from the distribution (can sometimes say random things)\n",
    "\n",
    "    Returns:\n",
    "        generator: yields the next symbol generated by the model\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create input tokens using the the tokenize function\n",
    "    input_tokens = tokenize(start_sentence, vocab_file=vocab_file, vocab_dir=vocab_dir)\n",
    "    \n",
    "    # Add batch dimension to array. Convert from (n,) to (x, n) where \n",
    "    # x is the batch size. Default is 1. (hint: you can use np.expand_dims() with axis=0)\n",
    "    input_tokens_with_batch = np.array(input_tokens)[None, :]\n",
    "    \n",
    "    # call the autoregressive_sample_stream function from trax\n",
    "    output_gen = trax.supervised.decoding.autoregressive_sample_stream( \n",
    "        # model\n",
    "        ReformerLM,\n",
    "        # inputs will be the tokens with batch dimension\n",
    "        inputs=input_tokens_with_batch,\n",
    "        # temperature\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    return output_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZK4hm3BPVQpX"
   },
   "outputs": [],
   "source": [
    "shape11 = trax.shapes.ShapeDtype((1, 1), dtype=np.int32)\n",
    "\n",
    "def attention(*args, **kwargs):\n",
    "    kwargs['predict_mem_len'] = 120  # max length for predictions\n",
    "    kwargs['predict_drop_len'] = 120  # never drop old stuff\n",
    "    return tl.SelfAttention(*args, **kwargs)\n",
    "\n",
    "model = ReformerLM(\n",
    "    vocab_size=33000,\n",
    "    n_layers=6,\n",
    "    mode='predict',\n",
    "    attention_type=attention,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tdmeEjJVQpX"
   },
   "outputs": [],
   "source": [
    "model.init_from_file('chatbot_model1.pkl.gz',\n",
    "                     weights_only=True, input_signature=shape11)\n",
    "\n",
    "STARTING_STATE = model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWoBrf3sVQpX"
   },
   "outputs": [],
   "source": [
    "def generate_dialogue(ReformerLM, model_state, start_sentence, vocab_file, vocab_dir, max_len, temperature):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ReformerLM:  the Reformer language model you just trained\n",
    "        model_state (np.array): initial state of the model before decoding\n",
    "        start_sentence (string): starting sentence of the conversation\n",
    "        vocab_file (string): vocabulary filename\n",
    "        vocab_dir (string): directory of the vocabulary file\n",
    "        max_len (int): maximum number of tokens to generate \n",
    "        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n",
    "            0.0: same as argmax, always pick the most probable token\n",
    "            1.0: sampling from the distribution (can sometimes say random things)\n",
    "\n",
    "    Returns:\n",
    "        generator: yields the next symbol generated by the model\n",
    "    \"\"\"  \n",
    "    \n",
    "    # define the delimiters we used during training\n",
    "    delimiter_1 = 'Person 1: ' \n",
    "    delimiter_2 = 'Person 2: '\n",
    "    \n",
    "    # initialize detokenized output\n",
    "    sentence = ''\n",
    "    \n",
    "    # token counter\n",
    "    counter = 0\n",
    "    \n",
    "    # output tokens. we insert a ': ' for formatting\n",
    "    result = [tokenize(': ', vocab_file=vocab_file, vocab_dir=vocab_dir)]\n",
    "    \n",
    "    # reset the model state when starting a new dialogue\n",
    "    ReformerLM.state = model_state\n",
    "    \n",
    "    # calls the output generator implemented earlier\n",
    "    output = ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, temperature=temperature)\n",
    "    \n",
    "    # print the starting sentence\n",
    "    print(start_sentence.split(delimiter_2)[0].strip())\n",
    "    \n",
    "    # loop below yields the next tokens until max_len is reached. the if-elif is just for prettifying the output.\n",
    "    for o in output:\n",
    "        \n",
    "        result.append(o)\n",
    "        \n",
    "        sentence = detokenize(np.concatenate(result, axis=0), vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)\n",
    "        \n",
    "        if sentence.endswith(delimiter_1):\n",
    "            sentence = sentence.split(delimiter_1)[0]\n",
    "            print(f'{delimiter_2}{sentence}')\n",
    "            sentence = ''\n",
    "            result.clear()\n",
    "        \n",
    "        elif sentence.endswith(delimiter_2):\n",
    "            sentence = sentence.split(delimiter_2)[0]\n",
    "            print(f'{delimiter_1}{sentence}')\n",
    "            sentence = ''\n",
    "            result.clear()\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "        if counter > max_len:\n",
    "            break    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYmVrQIbVQpY"
   },
   "source": [
    "We can now feed in different starting sentences and see how the model generates the dialogue. You can even input your own starting sentence. Just remember to ask a question that covers the topics in the Multiwoz dataset so you can generate a meaningful conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUiaa8vvVQpY",
    "outputId": "323ede16-ec79-4eed-c9a3-b388eb7940e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Are there theatres in town?\n",
      "Person 2: : There are 4 theatres in town. Do you have a preference? \n",
      "Person 1: Not really, but I would like the one in the south. \n",
      "Person 2: I have one theatre, the Junction, and the other is Tenpin. \n",
      "Person 1: Could I get the address and postcode? \n",
      "Person 1: The postcode is cb17gx, and the address is Clifton Way, Cambridge Leisure Park, Clifton Way. Is there anything else I can i give for? \n"
     ]
    }
   ],
   "source": [
    "sample_sentence = ' Person 1: Are there theatres in town? Person 2: '\n",
    "generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=120, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEObQyXtVQpY",
    "outputId": "6ec7977c-f8f7-4a93-a0e1-3064edc07d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Is there a hospital nearby?\n",
      "Person 2: : Addensbrookes Hospital is located at Hills Rd, Cambridge, postcode CB20QQ. Do you need a particular department? \n",
      "Person 1: No, I just need the phone number, please. \n",
      "Person 2: The phone number is 01223245151. \n",
      "Person 1: Thank you. That's all I need. \n",
      "Person 2: Thank you for using our services.Goodbye.\n",
      "Person 1: Goodbye. \n"
     ]
    }
   ],
   "source": [
    "sample_sentence = ' Person 1: Is there a hospital nearby? Person 2: '\n",
    "generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=120, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YeFr9O-VQpY",
    "outputId": "53efd67f-a696-4848-fc40-c12ba3729e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Can you book a taxi?\n",
      "Person 2: : I sure can. When would you like to leave? \n",
      "Person 1: I need to leave after 13:00. \n",
      "Person 2: I'd be happy to help with your request, first I will need to know your destination. \n",
      "Person 1: I'm going to be going to be from the city stop restaurant. \n",
      "Person 2: Booking completed! Booked car type\t:\tgrey volkswagen\n",
      "Contact number\t:\t07262372\n",
      " \n",
      "Person 2: Thank bybybybyby\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = ' Person 1: Can you book a taxi? Person 2: '\n",
    "generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=120, temperature=0.2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "C4_W4_Assignment.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "NLPC4-4"
   ]
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
